{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92a5719b-356a-45f3-8547-91ad21996d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# ----- In this example we we will use tensorflow callbacks such as EarlyStopping and ModelCheckpoint to monitor and modify the behaviour of model during training and evaluation.\n",
    "\n",
    "# ----- Load the MNIST dataset from TensorFlow's built-in datasets\n",
    "# MNIST is a collection of 70,000 handwritten digit images (0–9) used for training and testing image classification models\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# ----- Loaded the MNIST handwritten digits dataset.\n",
    "# It automatically downloads and splits data into:\n",
    "# x_train, y_train → training images and labels (60,000 samples)\n",
    "# x_test, y_test   → testing images and labels (10,000 samples)\n",
    "# Each image is 28x28 pixels (grayscale) and each label is a digit from 0–9.)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "# ------ Normalized the image pixel values so each image has values between 0 and 1.\n",
    "# This helps the model train faster and perform better by keeping all inputs on a similar scale.\n",
    "# 'axis=1' means normalization is done across each row of the image.\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)\n",
    "\n",
    "# Initialize a Sequential model — layers will be added one after another\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(), # Flatten layer converts 2D input (like 28x28 pixel images) into 1D array (784 values)\n",
    "                            # Needed before passing image data into Dense (fully connected) layers\n",
    "    keras.layers.Dense(128, activation='relu'), # First hidden layer with 128 neurons\n",
    "                                                # 'Dense' means fully connected — every input connects to every neuron\n",
    "                                                # 'relu' (Rectified Linear Unit) activation helps the model learn non-linear patterns efficiently\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10,  activation='softmax') # Output layer with 10 neurons — one for each class (e.g., digits 0–9 in MNIST dataset)\n",
    "                                                  # 'softmax' activation converts raw outputs into probabilities that sum to 1\n",
    "])\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Compile the model before training — this step defines how the model will learn\n",
    "model.compile(\n",
    "    optimizer='adam',                     # 'adam' is an adaptive optimizer that adjusts learning rate automatically for efficient training\n",
    "    loss='sparse_categorical_crossentropy', # Suitable for multi-class classification when labels are integers (not one-hot encoded)\n",
    "    metrics=['accuracy']                  # Tracks model performance — here, we measure how often predictions are correct\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a678e23c-9c06-4310-8aa6-701ca71afd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1489/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8552 - loss: 0.5168"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9149 - loss: 0.2910 - val_accuracy: 0.9542 - val_loss: 0.1503\n",
      "Epoch 2/10\n",
      "\u001b[1m1497/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9640 - loss: 0.1247"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9645 - loss: 0.1192 - val_accuracy: 0.9643 - val_loss: 0.1163\n",
      "Epoch 3/10\n",
      "\u001b[1m1489/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9771 - loss: 0.0743"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9749 - loss: 0.0799 - val_accuracy: 0.9680 - val_loss: 0.1040\n",
      "Epoch 4/10\n",
      "\u001b[1m1477/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9832 - loss: 0.0546"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9818 - loss: 0.0573 - val_accuracy: 0.9701 - val_loss: 0.1020\n",
      "Epoch 5/10\n",
      "\u001b[1m1495/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9879 - loss: 0.0388"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9864 - loss: 0.0431 - val_accuracy: 0.9723 - val_loss: 0.1012\n",
      "Epoch 6/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9894 - loss: 0.0327 - val_accuracy: 0.9682 - val_loss: 0.1095\n",
      "Epoch 7/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9909 - loss: 0.0261 - val_accuracy: 0.9693 - val_loss: 0.1190\n",
      "Epoch 8/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9933 - loss: 0.0210 - val_accuracy: 0.9713 - val_loss: 0.1153\n",
      "Epoch 9/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9942 - loss: 0.0170 - val_accuracy: 0.9691 - val_loss: 0.1332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17ac9a0f7d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Callbacks\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath='model.h5', save_best_only=True, monitor='val_loss')\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(x_train,y_train,epochs=10,validation_split=0.2,\n",
    "          callbacks=[early_stopping, model_checkpoint]) #epochs=10 → The model will go through the entire training dataset 10 times to learn patterns and minimize loss.\n",
    "                                   #Each epoch improves the model’s weights step by step, and the accuracy typically increases with more epochs (until overfitting occurs).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "434b923b-18d5-439a-aac8-43da98749980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9735 - loss: 0.0890\n",
      "0.08895895630121231 0.9735000133514404\n"
     ]
    }
   ],
   "source": [
    "#Next thing we are gonna do is calculate the validation loss and vaidation accuracy\n",
    "\n",
    "# Evaluate the trained model on the test dataset\n",
    "# This checks how well the model performs on data it hasn't seen before\n",
    "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "# Print the test loss (error) and accuracy\n",
    "# Lower loss and higher accuracy indicate better model performance\n",
    "print(val_loss, val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9a6feae-fb1e-4449-88d5-cb5ae6528935",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 27/313\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 8 variables whereas the saved optimizer has 14 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "[[6.49639995e-11 2.63353343e-07 1.06383834e-06 ... 9.99984503e-01\n",
      "  9.52191836e-09 4.90371903e-08]\n",
      " [4.36293715e-13 1.15134135e-05 9.99988437e-01 ... 8.03053013e-10\n",
      "  4.43622326e-11 1.15600964e-14]\n",
      " [7.12979942e-09 9.99977946e-01 6.37853191e-07 ... 1.57381983e-05\n",
      "  3.77063543e-06 1.46867682e-08]\n",
      " ...\n",
      " [1.42591425e-11 1.33005367e-08 1.28767122e-10 ... 1.72021402e-07\n",
      "  1.04316698e-08 1.42018007e-06]\n",
      " [5.99325040e-06 6.36021184e-07 2.32088311e-07 ... 5.77377762e-07\n",
      "  5.41474961e-04 4.68613370e-10]\n",
      " [1.24204060e-08 1.43447476e-08 6.87629793e-08 ... 1.95887143e-11\n",
      "  2.16646834e-09 2.80143048e-10]]\n"
     ]
    }
   ],
   "source": [
    "# Save model \n",
    "model.save('my_model.keras') # Save the entire trained model (architecture + weights + optimizer state) \n",
    "                             # This allows you to reload the model later without retraining.\n",
    "\n",
    "# Load the saved model\n",
    "new_model = tf.keras.models.load_model('my_model.keras')\n",
    "\n",
    "# --- Making predictions with the loaded model ---\n",
    "# Use the reloaded model to make predictions on the test dataset.\n",
    "# The model outputs probabilities for each of the 10 classes (digits 0–9 in MNIST).\n",
    "predictions = new_model.predict(x_test)\n",
    "\n",
    "\n",
    "print(predictions) # --- Displaying predictions ---\n",
    "# Print the prediction results — each prediction is an array of 10 probabilities\n",
    "# showing the likelihood of the image belonging to each digit class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d115b676-47d3-46a8-9507-aee2a4e74418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.argmax(predictions[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b33d036f-7d02-4233-b02f-815e16e22470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAYAAACvDDbuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAELElEQVR4nO3dT2tcVRzH4Tt/gmlCqTYhaFstioTiQlxYXCuIr0BEcF8Q9+58DS6lb8GtuIkbcSFWcVFdiFqJNFZcFJpKzdgkMy5cKJxz4c5kJvpNnmf5y81wGT49cE6md3qTyWTSQJj+f30DMAvhEkm4RBIukYRLJOESSbhEEi6RhEukYdcLX+2/vsj7gKZpmmZr/GGn66y4RBIukYRLJOESSbhEEi6RhEsk4RJJuEQSLpGESyThEkm4RBIukYRLJOESSbhEEi6RhEsk4RJJuEQSLpGESyThEkm4RBIukTo/gonFGjy3WcxuvblWvXb1TjnrHdZfd/3650e5rf8tKy6RhEsk4RJJuEQSLpGcKhyz/spKdf7rK+uVaf3bat94+5Ni9u7aD9VrX7v+Qtdbi2LFJZJwiSRcIgmXSDZnx6x3+WJ1vr/a/TU++OzlYvbp+8+3XH2r+wsHseISSbhEEi6RhEsk4RLJqcIi9QfF6O7V2p92p/PUx+Xs8PuTeXrQxopLJOESSbhEEi6RbM4WaHjh8WK2t97r/Pu9cf3a5Y9uzHxPJ4UVl0jCJZJwiSRcIgmXSE4VFmi0WZ4qTOPsz/X/5YsVl1DCJZJwiSRcItmcLdCDC0udr+2Ny9nG1u3qtQez3tAJYsUlknCJJFwiCZdIwiWSU4U5GD55qTr/Y6P7utDfL2cHt3dmvaUTz4pLJOESSbhEEi6RbM7m4OCJx478Gmvf/jmHOzk9rLhEEi6RhEsk4RJJuERyqjAHo40zna8dPKzPl7/6sZgdznpDp4AVl0jCJZJwiSRcItmcTWn49OVitvtM97ex/7D+WKXDe7sz39NpZMUlknCJJFwiCZdIwiWSU4UpTVaWy1n3b4Bqzu548tc8WHGJJFwiCZdIwiWSzdmU7l95tPO1tc/ert68U73Wlm06VlwiCZdIwiWScIkkXCI5VWjR9rDme88Oitlg1PIaD8oPjR/s/HKk++JvVlwiCZdIwiWScIlkc9Zi96WL9R9M8dnbc9se1rwoVlwiCZdIwiWScIkkXCI5VWgxOtf93/RwVH8e2NIX3xWz8cx3xL9ZcYkkXCIJl0jCJZLNWYu7V+vfebO6Xb5lS5XP3TZN04z39uZ6T/zDiksk4RJJuEQSLpGESySnCk3TvPfT18XsnW+uVK/d3z5fzHptX7o7qZ82cHRWXCIJl0jCJZJwiWRz1jTNW1vXitlwt/7WPFKb3W/bnbEoVlwiCZdIwiWScIkkXCI5VWiaZvPal8VseKn+7LDfXyzny7/VPzDuD76LY8UlknCJJFwiCZdINmct2r4d50xlbhN2/Ky4RBIukYRLJOESSbhEEi6RhEsk4RJJuEQSLpGESyThEkm4RBIukYRLJOESqTeZePoweay4RBIukYRLJOESSbhEEi6RhEsk4RJJuET6C2ddeWuloFlaAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the pyplot submodule from matplotlib for displaying images\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.imshow(x_test[5,]) # Display the second test image (index 1)\n",
    "plt.axis('off') # Hide the axis ticks and labels for a cleaner display\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820bf7fe-84a0-4d5b-b47a-a44f77cdee0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5621a767-fad9-46b9-8414-0318ad033326",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
