{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92a5719b-356a-45f3-8547-91ad21996d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9236 - loss: 0.2605\n",
      "Epoch 2/4\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9667 - loss: 0.1064\n",
      "Epoch 3/4\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9777 - loss: 0.0708\n",
      "Epoch 4/4\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9831 - loss: 0.0521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e985dedc40>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# ----- Load the MNIST dataset from TensorFlow's built-in datasets\n",
    "# MNIST is a collection of 70,000 handwritten digit images (0–9) used for training and testing image classification models\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# ----- Loaded the MNIST handwritten digits dataset.\n",
    "# It automatically downloads and splits data into:\n",
    "# x_train, y_train → training images and labels (60,000 samples)\n",
    "# x_test, y_test   → testing images and labels (10,000 samples)\n",
    "# Each image is 28x28 pixels (grayscale) and each label is a digit from 0–9.)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "# ------ Normalized the image pixel values so each image has values between 0 and 1.\n",
    "# This helps the model train faster and perform better by keeping all inputs on a similar scale.\n",
    "# 'axis=1' means normalization is done across each row of the image.\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)\n",
    "\n",
    "# Initialize a Sequential model — layers will be added one after another\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(), # Flatten layer converts 2D input (like 28x28 pixel images) into 1D array (784 values)\n",
    "                            # Needed before passing image data into Dense (fully connected) layers\n",
    "    keras.layers.Dense(128, activation='relu'), # First hidden layer with 128 neurons\n",
    "                                                # 'Dense' means fully connected — every input connects to every neuron\n",
    "                                                # 'relu' (Rectified Linear Unit) activation helps the model learn non-linear patterns efficiently\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10,  activation='softmax') # Output layer with 10 neurons — one for each class (e.g., digits 0–9 in MNIST dataset)\n",
    "                                                  # 'softmax' activation converts raw outputs into probabilities that sum to 1\n",
    "])\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Compile the model before training — this step defines how the model will learn\n",
    "model.compile(\n",
    "    optimizer='adam',                     # 'adam' is an adaptive optimizer that adjusts learning rate automatically for efficient training\n",
    "    loss='sparse_categorical_crossentropy', # Suitable for multi-class classification when labels are integers (not one-hot encoded)\n",
    "    metrics=['accuracy']                  # Tracks model performance — here, we measure how often predictions are correct\n",
    ")\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(x_train,y_train,epochs=4) #epochs=4 → The model will go through the entire training dataset 4 times to learn patterns and minimize loss.\n",
    "                                   #Each epoch improves the model’s weights step by step, and the accuracy typically increases with more epochs (until overfitting occurs).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "434b923b-18d5-439a-aac8-43da98749980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9740 - loss: 0.0902\n",
      "0.09022323042154312 0.9739999771118164\n"
     ]
    }
   ],
   "source": [
    "#Next thing we are gonna do is calculate the validation loss and vaidation accuracy\n",
    "\n",
    "# Evaluate the trained model on the test dataset\n",
    "# This checks how well the model performs on data it hasn't seen before\n",
    "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "# Print the test loss (error) and accuracy\n",
    "# Lower loss and higher accuracy indicate better model performance\n",
    "print(val_loss, val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9a6feae-fb1e-4449-88d5-cb5ae6528935",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "[[7.0760747e-10 3.6303998e-08 2.6247992e-05 ... 9.9982089e-01\n",
      "  5.1213522e-09 6.5769001e-07]\n",
      " [2.8251963e-11 6.2810238e-07 9.9999774e-01 ... 1.1672377e-11\n",
      "  7.9894660e-09 1.7767595e-14]\n",
      " [6.2559756e-08 9.9986207e-01 1.0357725e-05 ... 5.4969154e-05\n",
      "  5.6638553e-05 3.5178516e-07]\n",
      " ...\n",
      " [7.8311846e-09 1.7825982e-06 7.0049557e-09 ... 2.9996379e-05\n",
      "  2.3488897e-07 7.8889530e-04]\n",
      " [4.3629836e-08 5.3904303e-09 7.9602049e-09 ... 3.0672663e-08\n",
      "  2.0052276e-03 2.8023224e-09]\n",
      " [3.5762582e-08 9.2307843e-08 3.2806122e-07 ... 6.1067783e-11\n",
      "  6.3620742e-10 7.8927719e-11]]\n"
     ]
    }
   ],
   "source": [
    "# Save model \n",
    "model.save('my_model.keras') # Save the entire trained model (architecture + weights + optimizer state) \n",
    "                             # This allows you to reload the model later without retraining.\n",
    "\n",
    "# Load the saved model\n",
    "new_model = tf.keras.models.load_model('my_model.keras')\n",
    "\n",
    "# --- Making predictions with the loaded model ---\n",
    "# Use the reloaded model to make predictions on the test dataset.\n",
    "# The model outputs probabilities for each of the 10 classes (digits 0–9 in MNIST).\n",
    "predictions = new_model.predict(x_test)\n",
    "\n",
    "\n",
    "print(predictions) # --- Displaying predictions ---\n",
    "# Print the prediction results — each prediction is an array of 10 probabilities\n",
    "# showing the likelihood of the image belonging to each digit class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d115b676-47d3-46a8-9507-aee2a4e74418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.argmax(predictions[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b33d036f-7d02-4233-b02f-815e16e22470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the pyplot submodule from matplotlib for displaying images\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.imshow(x_test[1]) # Display the second test image (index 1)\n",
    "plt.axis('off') # Hide the axis ticks and labels for a cleaner display\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820bf7fe-84a0-4d5b-b47a-a44f77cdee0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
